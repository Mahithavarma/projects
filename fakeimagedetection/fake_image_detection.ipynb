{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ra-6OS5xRcWz",
    "outputId": "75113539-7bfb-47de-de62-28ed8545282e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# I'm using Google Drive account from the Colab environment by importing the Google Colab library.\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "from tensorflow.keras import layers, Sequential, Input, Model\n",
    "#importing the callbacks that will be used to save our model checkpoints and halt training early if necessary.\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Resize, Normalize, ToTensor, Compose, RandomVerticalFlip, RandomHorizontalFlip, RandomPerspective, RandomInvert, RandomAutocontrast\n",
    "#Setting the path to the directory where our dataset is stored in our Google Drive account.\n",
    "drive.mount('/content/drive')\n",
    "dataset_path = '/content/drive/MyDrive/fake_image_detection'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "image_size is a tuple specifying the desired size of the images default is (256,256)\n",
    "batch_size is an integer representing the size of the batches to use during training default is 32.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "oX2DSWyjWKtD"
   },
   "outputs": [],
   "source": [
    "def get_dataset_split_tensorflow(directory, image_size=(256,256), batch_size=32):\n",
    "  train_data  = image_dataset_from_directory(directory=f'{dataset_path}/train', label_mode='binary', image_size=image_size, batch_size=batch_size)\n",
    "  val_data    = image_dataset_from_directory(directory=f'{dataset_path}/valid', label_mode='binary', image_size=image_size, batch_size=batch_size)\n",
    "  test_data   = image_dataset_from_directory(directory=f'{dataset_path}/test', label_mode='binary', image_size=image_size, batch_size=batch_size)\n",
    "\n",
    "  return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZYAUFW6BWMTZ",
    "outputId": "563e9748-1a0f-40e8-c4f4-099f690cc6d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 189 files belonging to 2 classes.\n",
      "Found 21 files belonging to 2 classes.\n",
      "Found 90 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_tensorflow, val_data_tensorflow, test_data_tensorflow = get_dataset_split_tensorflow(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "9dxLohkdWMgE"
   },
   "outputs": [],
   "source": [
    "# RandomFlip: flips the image randomly either horizontally or vertically.\n",
    "# RandomTranslation: Flips the image randomly, either horizontally or vertically.\n",
    "# RandomRotation: Within a given range, RandomRotation rotates the image at random.\n",
    "# RandomZoom: randomly increases the image's magnification within a certain range.\n",
    "# Rescaling: When rescaling, the image's pixel values are adjusted to fall between [0,1].\n",
    "\n",
    "data_augmentation = Sequential([layers.RandomFlip(\"horizontal_and_vertical\"), layers.RandomTranslation(0.3,0.3), layers.RandomRotation(0.4), layers.RandomZoom(0.4), layers.Rescaling(1./255)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The following functions define metrics for evaluating the performance of the model. \n",
    "get_recall() calculates the recall score, \n",
    "get_precision() calculates the precision score, and \n",
    "get_f1() calculates the F1 score, which is the harmonic mean of precision and recall. \n",
    "These functions use the Keras backend to perform the calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "pVL_DeBxWMmQ"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def get_recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def get_precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def get_f1(y_true, y_pred):\n",
    "    precision = get_precision(y_true, y_pred)\n",
    "    recall = get_recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The model consists of 4 convolutional layers with increasing number of filters(16, 32, 64, and 64 respectively),\n",
    "followed by batch normalization, ReLU activation function and max-pooling layer. Initialization techniques such as he_uniform and zeros biases help initialize the weights and batch normalization helps reduce training time and increase accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m5x7RI_3WMqC",
    "outputId": "7745e578-5490-45dc-fb9b-2552a08e2faf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 128, 128, 16)      448       \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 128, 128, 16)     64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_40 (Activation)  (None, 128, 128, 16)      0         \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 128, 128, 16)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 64, 64, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization_41 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_41 (Activation)  (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 64, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_42 (Activation)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 32, 32, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 16, 16, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_43 (Activation)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 256)               4194560   \n",
      "                                                                 \n",
      " batch_normalization_44 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_44 (Activation)  (None, 256)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,257,057\n",
      "Trainable params: 4,256,193\n",
      "Non-trainable params: 864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import initializers\n",
    "\n",
    "def CNNmodel(input_shape):\n",
    "    inputs = Input(shape=input_shape+(3,))\n",
    "    x = data_augmentation(inputs)\n",
    "\n",
    "    # 1st Convolutional Layer\n",
    "    x = layers.Conv2D(16, 3, strides = 2, kernel_initializer = 'he_uniform',\n",
    "    bias_initializer = initializers.Zeros(), padding = 'same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D(3, strides = 1, padding = 'same')(x)\n",
    "\n",
    "    # 2nd Convolutional Layer\n",
    "    x = layers.Conv2D(32, 3, strides = 2, kernel_initializer = 'he_uniform',\n",
    "    bias_initializer = initializers.Zeros(), padding = 'same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D(3, strides = 1, padding = 'same')(x)\n",
    "\n",
    "    # 3rd Convolutional Layer\n",
    "    x = layers.Conv2D(64, 3, strides = 2, kernel_initializer = 'he_uniform',\n",
    "    bias_initializer = initializers.Zeros(), padding = 'same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D(3, strides = 1, padding = 'same')(x)\n",
    "\n",
    "    # 4th Convolutional Layer\n",
    "    x = layers.Conv2D(64, 3, strides = 2, kernel_initializer = 'he_uniform',\n",
    "    bias_initializer = initializers.Zeros(), padding = 'same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D(3, strides = 1, padding='same')(x)\n",
    "\n",
    "    # Passing it to a Fully Connected layer\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    # 1st Fully Connected Layer\n",
    "    x = layers.Dense(256, kernel_initializer = 'he_uniform',\n",
    "    bias_initializer=initializers.Zeros())(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    # Output Layer\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model = CNNmodel(input_shape=(256,256))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now, i'm going to set the number of epochs to 1, by choosing the Adam optimizer and setting the loss function to binary cross-entropy. Then, the model is compiled with the optimizer, loss function, and metrics to evaluate during training (accuracy, F1 score, precision, and recall). \n",
    "Finally, the model is trained on the train_data_tensorflow dataset for the specified number of epochs, and the validation set is used to evaluate the model after each epoch. The training history is stored in the history variable for later analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pbKql2e5WxmZ",
    "outputId": "d272ec14-9a87-43b2-bff9-82c1144f2210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 25s 2s/step - loss: 1.5743 - accuracy: 0.4286 - get_f1: 0.3855 - get_precision: 0.4212 - get_recall: 0.3611 - val_loss: 13.1452 - val_accuracy: 0.4762 - val_get_f1: 0.6452 - val_get_precision: 0.4762 - val_get_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "epochs = 1\n",
    "optimizer = optimizers.Adam()\n",
    "loss = \"binary_crossentropy\"\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy',get_f1, get_precision, get_recall])\n",
    "history = model.fit(train_data_tensorflow, epochs=epochs, validation_data=val_data_tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Evaluating the performance of the trained model on the test dataset. \n",
    "It also calculates the loss, accuracy, f1 score, precision, and recall on the test dataset using the evaluate() method of the trained model. \n",
    "Atlast it prints the test accuracy, test recall, and test f1_score rounded to 4 decimal places using the print() function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1LNnd-oDWxy1",
    "outputId": "385bbad6-5850-440f-bfe3-b69c30338951"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 236ms/step - loss: 11.3481 - accuracy: 0.5000 - get_f1: 0.6618 - get_precision: 0.4976 - get_recall: 1.0000\n",
      "\n",
      "Test accuracy: 50.0\n",
      "Test recall: 100.0\n",
      "Test f1_score: 66.1791\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_f1, test_precision, test_recall = model.evaluate(test_data_tensorflow)\n",
    "print('\\nTest accuracy:', round(test_acc*100,4))\n",
    "print('Test recall:', round(test_recall*100,4))\n",
    "print('Test f1_score:', round(test_f1*100,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oI4ZU_RUyEy7"
   },
   "source": [
    "# Tuning the CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet function creates a model based on the ResNet50 architecture with some modifications. \n",
    "The ResNet50 model is first loaded with pre-trained ImageNet weights and then made non-trainable. \n",
    "It takes this pre-trained ResNet50 model as input and adds some fully connected layers on top of it to create the final model. It prints the summary of tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yMuW4AZqZNMG",
    "outputId": "90b9254e-b144-4ba5-89da-e768dfea2ce2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 8, 8, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 131072)            0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 131072)            0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1024)              134218752 \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 158,397,057\n",
      "Trainable params: 134,809,345\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import applications, regularizers\n",
    "\n",
    "def ResNet(pre_trained, input_shape):\n",
    "  inputs = Input(shape=input_shape+(3,))\n",
    "  x = data_augmentation(inputs)\n",
    "  x = pre_trained(x)\n",
    "  x = layers.Flatten()(x)\n",
    "  \n",
    "  x = layers.Dropout(0.5)(x) \n",
    "  x = layers.Dense(1024, activation=\"relu\")(x) \n",
    "  x = layers.Dense(512, activation=\"relu\")(x)  \n",
    "  x = layers.Dense(128, activation=\"relu\")(x) \n",
    "  output = layers.Dense(1, activation='sigmoid')(x)\n",
    "  return Model(inputs, output)\n",
    "\n",
    "pre_trained = applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(256,256,3),\n",
    ")\n",
    "    \n",
    "pre_trained.trainable = False\n",
    "\n",
    "tuned_model = ResNet(pre_trained, input_shape=(256,256))\n",
    "tuned_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "defining an optimizer, loss function, and compiles a pre-trained ResNet50 model for binary classification. It then trains the model for 10 epochs using the specified optimizer and loss function on training data, and evaluates its performance on validation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uToVH5tSZUjL",
    "outputId": "0cd0c4d1-3e4b-4384-f5f4-dcc83ca60c1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 80s 12s/step - loss: 823.6858 - acc: 0.3915 - get_f1: 0.2810 - get_precision: 0.1979 - get_recall: 0.5000 - val_loss: 52.1271 - val_acc: 0.5238 - val_get_f1: 0.0000e+00 - val_get_precision: 0.0000e+00 - val_get_recall: 0.0000e+00\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 71s 12s/step - loss: 27.7219 - acc: 0.4762 - get_f1: 0.2126 - get_precision: 0.1562 - get_recall: 0.3333 - val_loss: 60.0396 - val_acc: 0.4762 - val_get_f1: 0.6452 - val_get_precision: 0.4762 - val_get_recall: 1.0000\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 70s 12s/step - loss: 50.7070 - acc: 0.4868 - get_f1: 0.4349 - get_precision: 0.3281 - get_recall: 0.6667 - val_loss: 28.1774 - val_acc: 0.5238 - val_get_f1: 0.0000e+00 - val_get_precision: 0.0000e+00 - val_get_recall: 0.0000e+00\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 71s 12s/step - loss: 14.7175 - acc: 0.5556 - get_f1: 0.3575 - get_precision: 0.2816 - get_recall: 0.5000 - val_loss: 11.0460 - val_acc: 0.4762 - val_get_f1: 0.6452 - val_get_precision: 0.4762 - val_get_recall: 1.0000\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 72s 12s/step - loss: 8.3971 - acc: 0.5079 - get_f1: 0.2264 - get_precision: 0.1719 - get_recall: 0.3333 - val_loss: 4.8047 - val_acc: 0.5238 - val_get_f1: 0.0000e+00 - val_get_precision: 0.0000e+00 - val_get_recall: 0.0000e+00\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 72s 12s/step - loss: 2.5815 - acc: 0.5556 - get_f1: 0.4648 - get_precision: 0.3642 - get_recall: 0.6458 - val_loss: 2.2960 - val_acc: 0.5238 - val_get_f1: 0.0000e+00 - val_get_precision: 0.0000e+00 - val_get_recall: 0.0000e+00\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 73s 12s/step - loss: 1.9838 - acc: 0.5238 - get_f1: 0.2336 - get_precision: 0.1800 - get_recall: 0.3333 - val_loss: 1.8749 - val_acc: 0.4762 - val_get_f1: 0.6452 - val_get_precision: 0.4762 - val_get_recall: 1.0000\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 71s 12s/step - loss: 1.1032 - acc: 0.4921 - get_f1: 0.4373 - get_precision: 0.3288 - get_recall: 0.6667 - val_loss: 1.0375 - val_acc: 0.5238 - val_get_f1: 0.0000e+00 - val_get_precision: 0.0000e+00 - val_get_recall: 0.0000e+00\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 70s 12s/step - loss: 1.1206 - acc: 0.4603 - get_f1: 0.3159 - get_precision: 0.2310 - get_recall: 0.5000 - val_loss: 0.8037 - val_acc: 0.5238 - val_get_f1: 0.0000e+00 - val_get_precision: 0.0000e+00 - val_get_recall: 0.0000e+00\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 70s 12s/step - loss: 0.8667 - acc: 0.5132 - get_f1: 0.2296 - get_precision: 0.1753 - get_recall: 0.3333 - val_loss: 0.8637 - val_acc: 0.4762 - val_get_f1: 0.6452 - val_get_precision: 0.4762 - val_get_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "epochs = 10\n",
    "optimizer = optimizers.Adam(learning_rate=0.01)\n",
    "loss = losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "tuned_model.compile(optimizer=optimizer, loss=loss, metrics=['acc', get_f1, get_precision, get_recall])\n",
    "history = tuned_model.fit(train_data_tensorflow, epochs=epochs, validation_data=val_data_tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Evaluating the performance of the tuned_model on the test dataset and prints the accuracy, recall, and F1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FCQ972nWya78",
    "outputId": "b606b2c5-ec20-4fd1-c2d8-b4f46128cd9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 24s 7s/step - loss: 0.8353 - acc: 0.5000 - get_f1: 0.6688 - get_precision: 0.5072 - get_recall: 1.0000\n",
      "\n",
      "Test accuracy: 50.0\n",
      "Test recall: 100.0\n",
      "Test f1_score: 66.8783\n"
     ]
    }
   ],
   "source": [
    "test_loss_tuned, test_acc_tuned, test_f1_tuned, test_precision_tuned, test_recall_tuned = tuned_model.evaluate(test_data_tensorflow)\n",
    "print('\\nTest accuracy:', round(test_acc_tuned*100,4))\n",
    "print('Test recall:', round(test_recall_tuned*100,4))\n",
    "print('Test f1_score:', round(test_f1_tuned*100,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Training a CNN model with different combinations of optimizers and regularizers and evaluates them on a test dataset. The early stopping callback is used to stop training if validation loss does not improve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zM5I_0svGdK2",
    "outputId": "640ef017-d4e3-43e6-c6d4-4fe0c3998962"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6/6 [==============================] - 15s 2s/step - loss: 0.8885 - accuracy: 0.4762 - val_loss: 1.2168 - val_accuracy: 0.4762\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.8210 - accuracy: 0.4868 - val_loss: 0.7177 - val_accuracy: 0.4762\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.8455 - accuracy: 0.4762 - val_loss: 0.8215 - val_accuracy: 0.4762\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.7575 - accuracy: 0.5132 - val_loss: 0.6305 - val_accuracy: 0.6667\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.7557 - accuracy: 0.5450 - val_loss: 0.7287 - val_accuracy: 0.4762\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 0.8452 - accuracy: 0.4889\n",
      "\n",
      "Optimizer: <keras.optimizers.legacy.gradient_descent.SGD object at 0x7f8c445b9490>, \n",
      "Regularizer: <keras.regularizers.L1 object at 0x7f8c445b96d0>, \n",
      " loss: 0.8452138304710388, \n",
      " accuracy: 0.4888888895511627\n",
      "\n",
      "Epoch 1/5\n",
      "6/6 [==============================] - 15s 2s/step - loss: 0.8325 - accuracy: 0.4815 - val_loss: 0.6840 - val_accuracy: 0.5238\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 15s 3s/step - loss: 0.7435 - accuracy: 0.5238 - val_loss: 0.7866 - val_accuracy: 0.4762\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.7154 - accuracy: 0.5767 - val_loss: 1.2385 - val_accuracy: 0.4762\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.7091 - accuracy: 0.5820 - val_loss: 1.0279 - val_accuracy: 0.4762\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.7390 - accuracy: 0.5238 - val_loss: 1.0552 - val_accuracy: 0.4762\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 0.9727 - accuracy: 0.5000\n",
      "\n",
      "Optimizer: <keras.optimizers.legacy.gradient_descent.SGD object at 0x7f8c445b9490>, \n",
      "Regularizer: <keras.regularizers.L2 object at 0x7f8c445b93d0>, \n",
      " loss: 0.9727162718772888, \n",
      " accuracy: 0.5\n",
      "\n",
      "Epoch 1/5\n",
      "6/6 [==============================] - 15s 2s/step - loss: 0.7618 - accuracy: 0.5026 - val_loss: 1.9021 - val_accuracy: 0.4762\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.7776 - accuracy: 0.5714 - val_loss: 0.6701 - val_accuracy: 0.4762\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.7657 - accuracy: 0.5979 - val_loss: 0.7832 - val_accuracy: 0.4762\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.7293 - accuracy: 0.5132 - val_loss: 0.6958 - val_accuracy: 0.6667\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 14s 2s/step - loss: 0.7396 - accuracy: 0.5132 - val_loss: 0.8617 - val_accuracy: 0.4762\n",
      "3/3 [==============================] - 2s 439ms/step - loss: 0.8643 - accuracy: 0.5000\n",
      "\n",
      "Optimizer: <keras.optimizers.legacy.gradient_descent.SGD object at 0x7f8c445b9490>, \n",
      "Regularizer: <keras.regularizers.L1L2 object at 0x7f8c445b9a90>, \n",
      " loss: 0.8642911911010742, \n",
      " accuracy: 0.5\n",
      "\n",
      "Epoch 1/5\n",
      "6/6 [==============================] - 16s 2s/step - loss: 1.8933 - accuracy: 0.5291 - val_loss: 7.2067 - val_accuracy: 0.4762\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 14s 2s/step - loss: 1.0461 - accuracy: 0.5503 - val_loss: 0.5884 - val_accuracy: 0.7143\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 15s 2s/step - loss: 0.7744 - accuracy: 0.5132 - val_loss: 0.7618 - val_accuracy: 0.5238\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 14s 2s/step - loss: 0.7420 - accuracy: 0.5132 - val_loss: 1.5375 - val_accuracy: 0.4762\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 14s 2s/step - loss: 0.7153 - accuracy: 0.5397 - val_loss: 1.6059 - val_accuracy: 0.4762\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 1.7565 - accuracy: 0.5000\n",
      "\n",
      "Optimizer: <keras.optimizers.legacy.adam.Adam object at 0x7f8c445b9550>, \n",
      "Regularizer: <keras.regularizers.L1 object at 0x7f8c445b96d0>, \n",
      " loss: 1.7564785480499268, \n",
      " accuracy: 0.5\n",
      "\n",
      "Epoch 1/5\n",
      "6/6 [==============================] - 17s 2s/step - loss: 1.1671 - accuracy: 0.5238 - val_loss: 1.0884 - val_accuracy: 0.5714\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.9984 - accuracy: 0.4974 - val_loss: 2.6896 - val_accuracy: 0.4762\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.8759 - accuracy: 0.5291 - val_loss: 4.4948 - val_accuracy: 0.4762\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.7754 - accuracy: 0.5503 - val_loss: 2.6093 - val_accuracy: 0.4762\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.6981 - accuracy: 0.5767 - val_loss: 1.1563 - val_accuracy: 0.4286\n",
      "3/3 [==============================] - 2s 413ms/step - loss: 0.9641 - accuracy: 0.5444\n",
      "\n",
      "Optimizer: <keras.optimizers.legacy.adam.Adam object at 0x7f8c445b9550>, \n",
      "Regularizer: <keras.regularizers.L2 object at 0x7f8c445b93d0>, \n",
      " loss: 0.9641369581222534, \n",
      " accuracy: 0.5444444417953491\n",
      "\n",
      "Epoch 1/5\n",
      "6/6 [==============================] - 15s 2s/step - loss: 1.3545 - accuracy: 0.5185 - val_loss: 1.5588 - val_accuracy: 0.5714\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.9469 - accuracy: 0.5026 - val_loss: 1.7032 - val_accuracy: 0.2857\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.8206 - accuracy: 0.4709 - val_loss: 2.7614 - val_accuracy: 0.4762\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.7549 - accuracy: 0.5079 - val_loss: 1.7087 - val_accuracy: 0.4762\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 17s 3s/step - loss: 0.7160 - accuracy: 0.5344 - val_loss: 0.9083 - val_accuracy: 0.5238\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 0.8525 - accuracy: 0.5444\n",
      "\n",
      "Optimizer: <keras.optimizers.legacy.adam.Adam object at 0x7f8c445b9550>, \n",
      "Regularizer: <keras.regularizers.L1L2 object at 0x7f8c445b9a90>, \n",
      " loss: 0.852547287940979, \n",
      " accuracy: 0.5444444417953491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers, regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "learning_rate = 0.0001\n",
    "batch_size = 32\n",
    "num_epoch = 5\n",
    "optimizers = [optimizers.SGD(), optimizers.Adam()]\n",
    "regularizers = [regularizers.l1(0.01), regularizers.l2(0.01), regularizers.l1_l2(l1=0.01, l2=0.01)]\n",
    "\n",
    "\n",
    "for opt in optimizers:\n",
    "    for reg in regularizers:\n",
    "        model = CNNmodel(input_shape = (256, 256))\n",
    "        model.compile(\n",
    "            optimizer = opt,\n",
    "            loss = 'binary_crossentropy',\n",
    "            metrics = ['accuracy']\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            train_data_tensorflow,\n",
    "            epochs = num_epoch,\n",
    "            batch_size = batch_size,\n",
    "            validation_data = val_data_tensorflow,\n",
    "            callbacks = [early_stopping],\n",
    "            verbose = 1\n",
    "        )\n",
    "        # Evaluate the model\n",
    "        loss, acc = model.evaluate(test_data_tensorflow)\n",
    "        print(f'\\nOptimizer: {opt}, \\nRegularizer: {reg}, \\n loss: {loss}, \\n accuracy: {acc}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cebjZ5vKOSY-"
   },
   "source": [
    "Optimizer: optimizers.Adam()\n",
    "\n",
    "Regularizer: regularizers.l1_l2(l1=0.01, l2=0.01)\n",
    "\n",
    "Loss: 1.2607940435409546 \n",
    "\n",
    "Accuracy: 0.5444444417953491"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
